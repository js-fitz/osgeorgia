{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PRECINCT NAME MATCHING\n",
    "Takes multiple datasets with `county` and `precinct_name` columns and builds a cross-dataset reference table of precinct name variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jaro\n",
    "import config\n",
    "import folium\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from fuzzywuzzy import fuzz\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "config.data_dict = {}\n",
    "config.county_dict = {}\n",
    "d_types = ['SHP16', 'NOV18', 'SHP18', 'NOV20', 'SHP20'] # add more data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add more data:\n",
    "- Invent a string label for the new dataset and add it to `d_types` (above)\n",
    "- Create a new k:v pair in config.data_dict with data details (key should be the pre-selected d_type label)\n",
    "    - Follow the format of the other datasets in section **1b**\n",
    "    - Identify the name of the column describing County, set that as `county_col`\n",
    "    - Identify the names of the columns describing precincts (usually multiple), set the list as `precinct_cols`\n",
    "- Run the entire notebook\n",
    "- Use the verification methods at the end of the notebook to ID errors\n",
    "    - Use `replace_strs` to direct-edit specific typos \n",
    "    - Use `county_edit` to apply a cleaning function to precinct names in a specific county for a given dataset\n",
    "        - `source_col` is the column to apply to function to\n",
    "        - `target_col` is the column where the cleaned values will be written to\n",
    "            - Can be a new feature, or can be an existing feature (existing means overwriting original values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NOV18\n",
    "def convert_rockdale(ab):\n",
    "    if str(ab).lower()=='nan': return ab\n",
    "    rockdale_pmap = {'BA': 'Barkside',\n",
    "                     'BT': 'Bethel',\n",
    "                     'CO': 'Conyers',\n",
    "                     'FI': 'Fieldstone',\n",
    "                     'FS': 'Flat Shoals',\n",
    "                     'HC': 'Honey Creek',\n",
    "                     'HI': 'High Tower',\n",
    "                     'LA': 'The Lakes',\n",
    "                     'LO': 'Lorraine',\n",
    "                     'MA': 'Magnet',\n",
    "                     'MI': 'Milestead',\n",
    "                     'OT': 'Olde Town',\n",
    "                     'RO': 'Rockdale',\n",
    "                     'SM': 'Smyrna',\n",
    "                     'SP': 'St. Pius',\n",
    "                     'ST': 'Stanton'}\n",
    "    ab = ab.upper()\n",
    "    if ab in rockdale_pmap.keys():\n",
    "        return rockdale_pmap[ab]\n",
    "    else: return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SHP18\n",
    "def convert_spalding(n):\n",
    "    if str(n).lower()=='nan': return n\n",
    "    if len(n)<2: return'0'+n\n",
    "    else: return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NOV20\n",
    "def get_barrow_num(x):\n",
    "    if str(x).lower()=='nan': return x\n",
    "    return x.split()[0]\n",
    "\n",
    "def get_barrow_name(x):\n",
    "    if str(x).lower()=='nan': return x\n",
    "    return ' '.join(re.findall('[A-Za-z]*', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1b. Define data params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dict['SHP16'] = {\n",
    "    'county_col': 'CTYNAME',\n",
    "    'precinct_cols': ['PRECINCT_I', 'PRECINCT_N'],\n",
    "    # although there are multiple version of this dataset, we assume precinct names remain consistent within\n",
    "    'fpath': '../../shapes/precincts_2016/GA_precincts16.shp',\n",
    "    'replace_strs' : { },\n",
    "    'county_edits': [ ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dict['NOV18'] = {\n",
    "    'county_col': 'County',\n",
    "    'precinct_cols': ['PRECINCT ID', 'PRECINCT DESCRIPTION'],\n",
    "    # although there are multiple version of this dataset, we assume precinct names remain consistent within\n",
    "    'fpath': '../2018_november/participation_demography/by_precinct/democrats.csv',\n",
    "    'replace_strs' : {\n",
    "        'austin \\(dun\\)': 'austin', # need to escape ()'s for .str.replace in pandas\n",
    "        'avondale \\(avo\\)': 'avondale',\n",
    "        'lithonia \\(lit\\)': 'lithonia',\n",
    "        'woodward \\(bhavn\\)': 'woodward',\n",
    "        'fbc - flc': 'family life center',\n",
    "    },\n",
    "    'county_edits': [{\n",
    "        'county': 'rockdale',\n",
    "        'target_col': 'PRECINCT DESCRIPTION',\n",
    "        'convert_func': convert_rockdale, # this function is defined above!\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dict['SHP18'] = {\n",
    "    'county_col': 'locality',\n",
    "    'precinct_cols': ['prec_shp', 'prec_elec'],\n",
    "    'fpath': '../../shapes/precincts_2018/2018Precincts.shp',\n",
    "    'replace_strs' : {\n",
    "        'hoggard mill': 'hoggards mill',\n",
    "        'south mill': 'south milledgeville',\n",
    "        'north mill': 'north milledgeville',\n",
    "        'bethlehem church - 211': 'bethlehem church',\n",
    "        'chattahoochee acvitity center': 'activity center' ,\n",
    "        'cjc': '#3 cjc',\n",
    "    },\n",
    "    'county_edits': [{\n",
    "        'county': 'spalding',\n",
    "        'target_col': 'prec_shp',\n",
    "        'convert_func': convert_spalding,\n",
    "    },{\n",
    "        'county': 'barrow',\n",
    "        'source_col': 'prec_elec',\n",
    "        'target_col': 'prec_elec',\n",
    "        'convert_func': get_barrow_num,\n",
    "    },]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dict['SHP20'] = {\n",
    "    'county_col': 'CTYNAME',\n",
    "    'precinct_cols': ['PRECINCT_I', 'PRECINCT_N'],\n",
    "    'fpath': '../../shapes/precincts_2020/ga_2020_general.shp',\n",
    "    'replace_strs' : {\n",
    "        'hoggard mill': 'hoggards mill',\n",
    "        'south mill': 'south milledgeville',\n",
    "        'north mill': 'north milledgeville',\n",
    "        'bethlehem church - 211': 'bethlehem church',\n",
    "        'chattahoochee acvitity center': 'activity center' ,\n",
    "        'cjc': '#3 cjc',\n",
    "    },\n",
    "    'county_edits': False, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dict['NOV20'] = {\n",
    "    'county_col': 'County',\n",
    "    'precinct_cols': ['Precinct'],\n",
    "    'fpath': '../2020_november/candidate_votes/by_precinct/US Senate (Loeffler) - Special.csv',\n",
    "    'replace_strs' : {\n",
    "        '03 Hmong New Hope Alliance Church 6364':'bramlett elementary',\n",
    "        '04 Covenant Life Sanctuary': 'westside middle',\n",
    "    },\n",
    "    'county_edits': [{\n",
    "        'county': 'barrow',\n",
    "        'source_col': 'Precinct',\n",
    "        'target_col': 'Precinct ID',\n",
    "        'convert_func': get_barrow_num,\n",
    "    },\n",
    "       {'county': 'barrow',\n",
    "        'target_col': 'Precinct',\n",
    "        'convert_func': get_barrow_name,\n",
    "    }]  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_key):    \n",
    "    print(f'> Reading {data_key}...')\n",
    "    data = config.data_dict[data_key].copy()\n",
    "    \n",
    "    # read data\n",
    "    if 'SHP' in data_key: df = gp.read_file(data['fpath'])\n",
    "    else: df = pd.read_csv(data['fpath'])\n",
    "\n",
    "    # isolate & clean column names\n",
    "    df = df[ [data['county_col']] + data['precinct_cols'] ]\n",
    "    df = df.rename(columns={data['county_col']: 'county'})\n",
    "    df.dropna(subset=['county'], inplace=True)\n",
    "    \n",
    "    # create \"_CLEAN\" lowercase version columns\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        df[c+'_CLEAN'] = df[c].str.lower().copy()\n",
    "       \n",
    "    # fix specific typos\n",
    "    typos_fixed = 0\n",
    "    for o, n in data['replace_strs'].items():\n",
    "        for c in cols: # assigns edits to CLEAN version of column\n",
    "            fixed = df[c+'_CLEAN'].str.replace( o.lower(), n.lower() ).copy()\n",
    "            # calc how many values were affected by the edit (for log)\n",
    "            typos_fixed += (fixed.dropna().values != df[c+'_CLEAN'].dropna().values).sum() \n",
    "            df[c+'_CLEAN'] = fixed # assign edits\n",
    "    print(f\"  > {typos_fixed}/{len(data['replace_strs'])} typos fixed\")\n",
    "    \n",
    "    # county-specific edit functions\n",
    "    # given_function('source_col')——>'target_col'\n",
    "    c_edits = config.data_dict[data_key]['county_edits']\n",
    "    if c_edits:\n",
    "        for ce in c_edits:\n",
    "            c_idx = df[df.county.str.lower()==ce['county'].lower()].index\n",
    "            # create new column if target doesn't exist\n",
    "            if 'source_col' not in ce.keys():\n",
    "                ce['source_col'] = ce['target_col']            \n",
    "            # assign the pre-made function:\n",
    "            df.loc[c_idx, ce['target_col']+'_CLEAN'\n",
    "                  ] = df.loc[c_idx, ce['source_col']\n",
    "                  ].apply(ce['convert_func'])\n",
    "            \n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True) # ******** MAYBE DON'T DO THIS\n",
    "    \n",
    "    # save cleaned df to data_dict\n",
    "    config.data_dict[data_key]['data'] = df\n",
    "\n",
    "    # re-iterate over found data for all counties to build county_dict\n",
    "    all_counties = list(df.county_CLEAN.unique())\n",
    "    for county in all_counties:\n",
    "        if county not in config.county_dict.keys():\n",
    "            config.county_dict[county] = {}\n",
    "        c_data = df[df.county_CLEAN.str.lower()==county.lower()]\n",
    "        c_data = c_data[[c for c in c_data.columns\n",
    "                         if 'county' not in c]] # drop county col\n",
    "        config.county_dict[county][d_key  # store county data in county_dict\n",
    "                                  ] = c_data.reset_index(drop=True)\n",
    "    \n",
    "    # log\n",
    "    n_precs = max([df[c+'_CLEAN'].nunique() for c in data['precinct_cols']])\n",
    "    print('  >', len(all_counties), 'counties')\n",
    "    print('  >', n_precs, 'precincts')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1c. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading SHP16...\n",
      "  > 0/0 typos fixed\n",
      "  > 159 counties\n",
      "  > 2555 precincts\n",
      "\n",
      "> Reading NOV18...\n",
      "  > 5/5 typos fixed\n",
      "  > 159 counties\n",
      "  > 2533 precincts\n",
      "\n",
      "> Reading SHP18...\n",
      "  > 12/6 typos fixed\n",
      "  > 159 counties\n",
      "  > 2568 precincts\n",
      "\n",
      "> Reading NOV20...\n",
      "  > 1/2 typos fixed\n",
      "  > 159 counties\n",
      "  > 2556 precincts\n",
      "\n",
      "> Reading SHP20...\n",
      "  > 4/6 typos fixed\n",
      "  > 159 counties\n",
      "  > 2573 precincts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d_key in d_types:\n",
    "    read_data(d_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Find matches across all datasets in one county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order datasets by top number of precincts (to sort the joining process)\n",
    "def sort_datasets(county):\n",
    "\n",
    "    p_counts = {} # to store n_precincts per dataset (in this county)\n",
    "    c_dict = config.county_dict[county] # load existing data for this county\n",
    "    for add_d_key in list(c_dict.keys()): # datasets available for this county\n",
    "\n",
    "        data = config.data_dict[add_d_key].copy() # metadata\n",
    "        add_data = c_dict[add_d_key].copy() #df\n",
    "\n",
    "        # don't count absentee columns\n",
    "        n_precincts = max(\n",
    "            [add_data[p_col].nunique()\n",
    "             for p_col in data['precinct_cols']]) \n",
    "        p_counts[add_d_key] = n_precincts\n",
    "\n",
    "    # sorted datasets by top n_precincts (in this county)\n",
    "    top_d_types = {k: v for k, v in\n",
    "                    sorted(p_counts.items(),\n",
    "                    key=lambda item: item[1])[::-1]}\n",
    "    return top_d_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build joined reference table, starting with the dataset with the most precincts \n",
    "def build_aka_table(county, verb=False):\n",
    "\n",
    "    top_d_types = sort_datasets(county) # get dataset add order\n",
    "    \n",
    "    for i, d_add_key in enumerate(top_d_types): # iterate datasets \n",
    "\n",
    "        # target existing data\n",
    "        c_dict = config.county_dict[county]\n",
    "        df = c_dict[d_add_key].copy()\n",
    "        # add datatype specifier to column names\n",
    "        df.rename(columns={\n",
    "            c:d_add_key+'_'+c for c in df.columns}, inplace=True)\n",
    "        \n",
    "        \n",
    "        # find or create new 'joined' table for this county\n",
    "        if 'joined' not in c_dict.keys(): \n",
    "            # if new, instantiate \"joined\" as the first (biggest) existing data\n",
    "            config.county_dict[county]['joined'] = df\n",
    "            continue # done with this dataset\n",
    "        # load existing joined data\n",
    "        else: pre_joined = config.county_dict[county]['joined'].copy()\n",
    "\n",
    "        # identify columns to compare over\n",
    "        pre_cols = [c for c in pre_joined.columns if 'CLEAN' in c]\n",
    "        new_cols = [c for c in df.columns if 'CLEAN' in c]\n",
    "\n",
    "        \n",
    "        # SEARCH FOR MATCHES...\n",
    "        match_hist_idx = {}\n",
    "\n",
    "        # for each new row ...\n",
    "        for n_i in df.index:\n",
    "            best_score = .75\n",
    "            perfect_find = False\n",
    "            new_row = df.loc[n_i]\n",
    "\n",
    "            # for each val (comp col) in new row...\n",
    "            for new_ccol in new_cols:\n",
    "                if perfect_find: break\n",
    "                n_val = new_row[new_ccol]\n",
    "                if str(n_val).lower() in ['nan', '88888', '99999']: continue\n",
    "\n",
    "                # for each existing feature name... (comp col)\n",
    "                for pre_ccol in pre_cols:\n",
    "                    if perfect_find: break\n",
    "                    pre_series = pre_joined[pre_ccol].dropna() \n",
    "\n",
    "                    # for each val in comp col\n",
    "                    for p_i, p_val in dict(pre_series).items():\n",
    "                        if perfect_find: break\n",
    "                        if str(n_val).lower() in ['nan', '88888', '99999']: continue\n",
    "\n",
    "                        # PERFECT MATCH    \n",
    "                        if n_val==p_val:\n",
    "                            match_hist_idx[n_i] = p_i\n",
    "                            perfect_find = True\n",
    "\n",
    "                        # JARO MATCH\n",
    "                        else:\n",
    "                            j_score = jaro.jaro_metric(n_val.upper(), p_val.upper())\n",
    "                            if j_score > best_score:\n",
    "                                best_score = j_score\n",
    "                                match_hist_idx[n_i] = p_i\n",
    "\n",
    "                                \n",
    "        # DATA MATCH LOG\n",
    "        could_match = df.copy()\n",
    "        for c in new_cols:\n",
    "            could_match = could_match[(could_match[c]!='99999') &\n",
    "                                      (could_match[c]!='88888')]\n",
    "        #could_match = could_match.dropna()\n",
    "        \n",
    "        pct_found = round(100*(len(match_hist_idx)/len(could_match)), 1)\n",
    "        if verb and pct_found<90:\n",
    "            print(f'{county.upper()} ——— {d_add_key} >>> M: {pct_found}%')\n",
    "        \n",
    "        # COUNTY LOG\n",
    "        config.county_dict[county][d_add_key+'_SEARCHED'] = len(df)\n",
    "        config.county_dict[county][d_add_key+'_FOUND'] = len(match_hist_idx)\n",
    "        config.county_dict[county][d_add_key+'_MRATE'] = pct_found\n",
    "        \n",
    "        # all comparisons done for this dataset....\n",
    "        # ASSIGN MATCHES (index vals) to 'joined' dataframe\n",
    "        pre_joined['match_idx'] = np.nan # empty init\n",
    "        for n_i in df.index:\n",
    "            if n_i in match_hist_idx.keys(): # if found, assign index of match\n",
    "                pre_joined.loc[match_hist_idx[n_i], 'match_idx'] = n_i              \n",
    "\n",
    "        # merge & updated county 'join' table \n",
    "        new_joined = pd.merge(pre_joined, df, how='outer',\n",
    "                              left_on='match_idx', right_index=True)\n",
    "        new_joined.drop('match_idx', axis=1, inplace=True)\n",
    "        new_joined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # write new merge back over county_dict\n",
    "        config.county_dict[county]['joined'] = new_joined.copy()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Iterate all counties to find matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154d66e819eb40c88bc5451cf15a8d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPALDING ——— NOV20 >>> M: 77.8%\n",
      "BUTTS ——— NOV18 >>> M: 0.0%\n",
      "LAURENS ——— SHP16 >>> M: 88.2%\n",
      "JACKSON ——— NOV18 >>> M: 0.0%\n",
      "CHATTAHOOCHEE ——— SHP18 >>> M: 50.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counties = config.county_dict.keys()\n",
    "for county in tqdm(counties):\n",
    "    build_aka_table(county, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Review matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHP16:  99.8% found\n",
      "NOV18:  96.8% found\n",
      "SHP18:  99.8% found\n",
      "NOV20:  99.7% found\n",
      "SHP20:  99.9% found\n"
     ]
    }
   ],
   "source": [
    "def print_match_rate(d_add_key):\n",
    "    total_searched = 0\n",
    "    total_found = 0\n",
    "    for v in config.county_dict.values():\n",
    "        try: total_searched += v[d_add_key+'_SEARCHED']\n",
    "        except: pass\n",
    "        try: total_found += v[d_add_key+'_FOUND']\n",
    "        except: pass\n",
    "\n",
    "    pct_found = (round(total_found / total_searched, 3)*100)\n",
    "    \n",
    "    print(f\"{d_add_key}:  {pct_found}% found\")\n",
    "    \n",
    "for d in d_types:\n",
    "    print_match_rate(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assess addtl required edits here & add `county_edits` or `replace_strings` to the problem data as needed.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Merge all counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame()\n",
    "\n",
    "for county, data in config.county_dict.items():\n",
    "\n",
    "    county_precs = data['joined']\n",
    "    county_precs['county'] = county\n",
    "    out = pd.concat([out, data['joined']])\n",
    "    \n",
    "out.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Infer precinct names & codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>precinct_name</th>\n",
       "      <th>precinct_id</th>\n",
       "      <th>SHP20_PRECINCT_I</th>\n",
       "      <th>SHP20_PRECINCT_N</th>\n",
       "      <th>SHP20_PRECINCT_I_CLEAN</th>\n",
       "      <th>SHP20_PRECINCT_N_CLEAN</th>\n",
       "      <th>NOV20_Precinct</th>\n",
       "      <th>NOV20_Precinct_CLEAN</th>\n",
       "      <th>NOV20_Precinct ID_CLEAN</th>\n",
       "      <th>...</th>\n",
       "      <th>NOV18_PRECINCT ID_CLEAN</th>\n",
       "      <th>NOV18_PRECINCT DESCRIPTION_CLEAN</th>\n",
       "      <th>SHP18_prec_shp</th>\n",
       "      <th>SHP18_prec_elec</th>\n",
       "      <th>SHP18_prec_shp_CLEAN</th>\n",
       "      <th>SHP18_prec_elec_CLEAN</th>\n",
       "      <th>SHP16_PRECINCT_I</th>\n",
       "      <th>SHP16_PRECINCT_N</th>\n",
       "      <th>SHP16_PRECINCT_I_CLEAN</th>\n",
       "      <th>SHP16_PRECINCT_N_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Appling</td>\n",
       "      <td></td>\n",
       "      <td>3C</td>\n",
       "      <td>3C</td>\n",
       "      <td>3C</td>\n",
       "      <td>3c</td>\n",
       "      <td>3c</td>\n",
       "      <td>3C</td>\n",
       "      <td>3c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3c</td>\n",
       "      <td>3c</td>\n",
       "      <td>3c</td>\n",
       "      <td>3C</td>\n",
       "      <td>3c</td>\n",
       "      <td>3c</td>\n",
       "      <td>3C</td>\n",
       "      <td>3C</td>\n",
       "      <td>3c</td>\n",
       "      <td>3c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>Appling</td>\n",
       "      <td></td>\n",
       "      <td>4B</td>\n",
       "      <td>4B</td>\n",
       "      <td>4B</td>\n",
       "      <td>4b</td>\n",
       "      <td>4b</td>\n",
       "      <td>4B</td>\n",
       "      <td>4b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4b</td>\n",
       "      <td>4b</td>\n",
       "      <td>4b</td>\n",
       "      <td>4B</td>\n",
       "      <td>4b</td>\n",
       "      <td>4b</td>\n",
       "      <td>4B</td>\n",
       "      <td>4B</td>\n",
       "      <td>4b</td>\n",
       "      <td>4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Appling</td>\n",
       "      <td></td>\n",
       "      <td>4A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A</td>\n",
       "      <td>4A</td>\n",
       "      <td>4a</td>\n",
       "      <td>4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>Appling</td>\n",
       "      <td></td>\n",
       "      <td>3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3B</td>\n",
       "      <td>3B</td>\n",
       "      <td>3b</td>\n",
       "      <td>3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Appling</td>\n",
       "      <td></td>\n",
       "      <td>5C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5C</td>\n",
       "      <td>5C</td>\n",
       "      <td>5c</td>\n",
       "      <td>5c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>Worth</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>SUMNER</td>\n",
       "      <td>4</td>\n",
       "      <td>sumner</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>sumner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>sumner</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>sumner</td>\n",
       "      <td>sumner</td>\n",
       "      <td>4</td>\n",
       "      <td>SUMNER</td>\n",
       "      <td>4</td>\n",
       "      <td>sumner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>Worth</td>\n",
       "      <td>Red Rock</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>RED ROCK</td>\n",
       "      <td>6</td>\n",
       "      <td>red rock</td>\n",
       "      <td>Red Rock</td>\n",
       "      <td>red rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>red rock</td>\n",
       "      <td>Red Rock</td>\n",
       "      <td>Red Rock</td>\n",
       "      <td>red rock</td>\n",
       "      <td>red rock</td>\n",
       "      <td>6</td>\n",
       "      <td>RED ROCK</td>\n",
       "      <td>6</td>\n",
       "      <td>red rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>Worth</td>\n",
       "      <td>Bridgeboro</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>BRIDGEBORO</td>\n",
       "      <td>12</td>\n",
       "      <td>bridgeboro</td>\n",
       "      <td>Bridgeboro</td>\n",
       "      <td>bridgeboro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>bridgeboro</td>\n",
       "      <td>Bridgeboro</td>\n",
       "      <td>Bridgeboro</td>\n",
       "      <td>bridgeboro</td>\n",
       "      <td>bridgeboro</td>\n",
       "      <td>12</td>\n",
       "      <td>BRIDGEBORO</td>\n",
       "      <td>12</td>\n",
       "      <td>bridgeboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>Worth</td>\n",
       "      <td>Poulan</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>POULAN</td>\n",
       "      <td>3</td>\n",
       "      <td>poulan</td>\n",
       "      <td>Poulan</td>\n",
       "      <td>poulan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>poulan</td>\n",
       "      <td>Poulan</td>\n",
       "      <td>Poulan</td>\n",
       "      <td>poulan</td>\n",
       "      <td>poulan</td>\n",
       "      <td>3</td>\n",
       "      <td>POULAN</td>\n",
       "      <td>3</td>\n",
       "      <td>poulan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>Worth</td>\n",
       "      <td>Piney Woods</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>PINEY WOODS</td>\n",
       "      <td>16</td>\n",
       "      <td>piney woods</td>\n",
       "      <td>Piney Woods</td>\n",
       "      <td>piney woods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>piney woods</td>\n",
       "      <td>Piney Woods</td>\n",
       "      <td>Piney Woods</td>\n",
       "      <td>piney woods</td>\n",
       "      <td>piney woods</td>\n",
       "      <td>16</td>\n",
       "      <td>PINEY WOODS</td>\n",
       "      <td>16</td>\n",
       "      <td>piney woods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       county precinct_name precinct_id SHP20_PRECINCT_I SHP20_PRECINCT_N  \\\n",
       "2041  Appling                        3C               3C               3C   \n",
       "2029  Appling                        4B               4B               4B   \n",
       "2031  Appling                        4A              NaN              NaN   \n",
       "2030  Appling                        3B              NaN              NaN   \n",
       "2034  Appling                        5C              NaN              NaN   \n",
       "...       ...           ...         ...              ...              ...   \n",
       "1728    Worth        Sumner           4                4           SUMNER   \n",
       "1724    Worth      Red Rock           6                6         RED ROCK   \n",
       "1735    Worth    Bridgeboro          12               12       BRIDGEBORO   \n",
       "1731    Worth        Poulan           3                3           POULAN   \n",
       "1734    Worth   Piney Woods          16               16      PINEY WOODS   \n",
       "\n",
       "     SHP20_PRECINCT_I_CLEAN SHP20_PRECINCT_N_CLEAN NOV20_Precinct  \\\n",
       "2041                     3c                     3c             3C   \n",
       "2029                     4b                     4b             4B   \n",
       "2031                    NaN                    NaN            NaN   \n",
       "2030                    NaN                    NaN            NaN   \n",
       "2034                    NaN                    NaN            NaN   \n",
       "...                     ...                    ...            ...   \n",
       "1728                      4                 sumner         Sumner   \n",
       "1724                      6               red rock       Red Rock   \n",
       "1735                     12             bridgeboro     Bridgeboro   \n",
       "1731                      3                 poulan         Poulan   \n",
       "1734                     16            piney woods    Piney Woods   \n",
       "\n",
       "     NOV20_Precinct_CLEAN NOV20_Precinct ID_CLEAN  ...  \\\n",
       "2041                   3c                     NaN  ...   \n",
       "2029                   4b                     NaN  ...   \n",
       "2031                  NaN                     NaN  ...   \n",
       "2030                  NaN                     NaN  ...   \n",
       "2034                  NaN                     NaN  ...   \n",
       "...                   ...                     ...  ...   \n",
       "1728               sumner                     NaN  ...   \n",
       "1724             red rock                     NaN  ...   \n",
       "1735           bridgeboro                     NaN  ...   \n",
       "1731               poulan                     NaN  ...   \n",
       "1734          piney woods                     NaN  ...   \n",
       "\n",
       "     NOV18_PRECINCT ID_CLEAN NOV18_PRECINCT DESCRIPTION_CLEAN SHP18_prec_shp  \\\n",
       "2041                      3c                               3c             3c   \n",
       "2029                      4b                               4b             4b   \n",
       "2031                     NaN                              NaN            NaN   \n",
       "2030                     NaN                              NaN            NaN   \n",
       "2034                     NaN                              NaN            NaN   \n",
       "...                      ...                              ...            ...   \n",
       "1728                       4                           sumner         Sumner   \n",
       "1724                       6                         red rock       Red Rock   \n",
       "1735                      12                       bridgeboro     Bridgeboro   \n",
       "1731                       3                           poulan         Poulan   \n",
       "1734                      16                      piney woods    Piney Woods   \n",
       "\n",
       "     SHP18_prec_elec SHP18_prec_shp_CLEAN SHP18_prec_elec_CLEAN  \\\n",
       "2041              3C                   3c                    3c   \n",
       "2029              4B                   4b                    4b   \n",
       "2031             NaN                  NaN                   NaN   \n",
       "2030             NaN                  NaN                   NaN   \n",
       "2034             NaN                  NaN                   NaN   \n",
       "...              ...                  ...                   ...   \n",
       "1728          Sumner               sumner                sumner   \n",
       "1724        Red Rock             red rock              red rock   \n",
       "1735      Bridgeboro           bridgeboro            bridgeboro   \n",
       "1731          Poulan               poulan                poulan   \n",
       "1734     Piney Woods          piney woods           piney woods   \n",
       "\n",
       "     SHP16_PRECINCT_I SHP16_PRECINCT_N SHP16_PRECINCT_I_CLEAN  \\\n",
       "2041               3C               3C                     3c   \n",
       "2029               4B               4B                     4b   \n",
       "2031               4A               4A                     4a   \n",
       "2030               3B               3B                     3b   \n",
       "2034               5C               5C                     5c   \n",
       "...               ...              ...                    ...   \n",
       "1728                4           SUMNER                      4   \n",
       "1724                6         RED ROCK                      6   \n",
       "1735               12       BRIDGEBORO                     12   \n",
       "1731                3           POULAN                      3   \n",
       "1734               16      PINEY WOODS                     16   \n",
       "\n",
       "     SHP16_PRECINCT_N_CLEAN  \n",
       "2041                     3c  \n",
       "2029                     4b  \n",
       "2031                     4a  \n",
       "2030                     3b  \n",
       "2034                     5c  \n",
       "...                     ...  \n",
       "1728                 sumner  \n",
       "1724               red rock  \n",
       "1735             bridgeboro  \n",
       "1731                 poulan  \n",
       "1734            piney woods  \n",
       "\n",
       "[3036 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work with clean cols only\n",
    "o_clean = out[[c for c in out.columns if 'CLEAN' in c]].copy()\n",
    "\n",
    "for r_idx in o_clean.index:\n",
    "    \n",
    "    r_vals = list(o_clean.loc[r_idx].dropna().values)\n",
    "    r_vals = set([c.upper() for c in r_vals]) \n",
    "    r_vals = {r: len(r) for r in r_vals}\n",
    "    \n",
    "    if r_vals:\n",
    "        longest = max(r_vals.items(), key=operator.itemgetter(1))[0]\n",
    "        shortest = min(r_vals.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "        if shortest in longest.split():\n",
    "            longest = ' '.join(longest.split(shortest))\n",
    "        \n",
    "        if shortest == longest:\n",
    "            nums_in_long = len([c for c in re.findall('[\\d]*', longest) if c!=''])\n",
    "            if len(longest) <= 8 and nums_in_long:\n",
    "                longest = ''\n",
    "            else: shortest = ''\n",
    "\n",
    "        shortest = shortest.upper()\n",
    "        \n",
    "        l_parts = longest.split('(')\n",
    "        \n",
    "        longest = ' '.join([l.capitalize() for l in l_parts[0].split()])\n",
    "        if len(l_parts)>1:\n",
    "            longest +=' ('+l_parts[1].lower()\n",
    "                \n",
    "        out.loc[r_idx, 'precinct_name'] = longest\n",
    "        out.loc[r_idx, 'precinct_id'] = shortest\n",
    "\n",
    "out = out[list(out.columns)[-3:] + list(out.columns)[:-3]]\n",
    "out.county = out.county.apply(lambda x: ' '.join([p.capitalize() for p in x.split()]))\n",
    "out.sort_values('precinct_name').sort_values('county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('precinct_nametable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
